import requests as req
import json
from bs4 import BeautifulSoup
from urllib.parse import quote


class NpEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, numpy.integer):
            return int(obj)
        if isinstance(obj, numpy.floating):
            return float(obj)
        if isinstance(obj, numpy.ndarray):
            return obj.tolist()
        return super(NpEncoder, self).default(obj)


def get_104(inputlist):
    isreturn = False
    d104 = {
        "å°åŒ—å¸‚": "6001001000",
        "æ–°åŒ—å¸‚": "6001002000",
        "æ¡ƒåœ’å¸‚": "6001005000",
        "å°ä¸­å¸‚": "6001008000",
        "å½°åŒ–ç¸£": "6001010000",
        "å°å—å¸‚": "6001014000",
        "é«˜é›„å¸‚": "6001016000"
    }
    arealist = inputlist[2].split(',')
    for i in range(len(arealist)):
        arealist[i] = quote(d104[arealist[i]], encoding='utf-8')

    returnstrbox = ""
    strbox = ""

    strbox += "\né æ•¸"+inputlist[3]+":---------------\n\n"
    url = "https://www.104.com.tw/jobs/search/list?ro=0&isnew=0&kwop=7&keyword="+inputlist[1]+"&expansionType=area%2Cspec%2Ccom%2Cjob%2Cwf%2Cwktm&area="+",".join(arealist)+"&order=12&asc=0&page=" + \
        inputlist[3] + \
        "&mode=s&langFlag=0&langStatus=0&recommendJob=1&hotJob=1"
    header = {

        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.83 Safari/537.36",
        "Cookie": "_T_MYPOOL_104I=1; luauid=1856058949; __auc=e2a4b43617fc089e8bc3555acf6; _gid=GA1.3.998545743.1648202738; _gcl_au=1.1.1205875470.1648210440; ALGO_EXP_6019=C; ALGO_EXP_12509=G; lup=1856058949.5001489413863.4623532291991.1.4507568175053; lunp=4623532291991; TS016ab800=01180e452d8660dfd738016151c3f15d8b58f9918a1302be5327335e918dbc6e071406788d496ae3c059aedc230fdef409766a17b9341963e66abdd39f38a692c822c4b95dcca090104d76c9b207a0407a9d6d0ace; __asc=2d4c1b7d17fc4554417b552a4a4; _dc_gtm_UA-15276226-1=1; _ga_W9X1GB1SVR=GS1.1.1648266396.3.1.1648266408.48; _ga_FJWMQR9J2K=GS1.1.1648266396.4.1.1648266408.48; _ga=GA1.3.1948524712.1648202738",
        "Referer": "https://www.104.com.tw/jobs/search/"}
    request = req.get(url, headers=header)
    data = request.json()
    with open("data.json", "w") as f:
        json.dump(data, f, indent=4)

    for i in data["data"]["list"]:
        try:
            appearDateDesc = i["appearDateDesc"]  # ä¸Šå‚³æ™‚é–“
            coIndustryDesc = i["coIndustryDesc"]  # å·¥ä½œé¡žåˆ¥
            # description = i["description"]  # å·¥ä½œéœ€

            jobAddrNoDesc = i["jobAddrNoDesc"]+i["jobAddress"]  # å·¥ä½œåœ°é»ž
            salaryDesc = i["salaryDesc"]  # è–ªæ°´
            link = i["link"]["job"]  # é€£çµ
            strbox += i["jobName"] + \
                f"\n----------------------\nä¸Šå‚³æ™‚é–“:{appearDateDesc}\nè–ªè³‡ï¼š{salaryDesc}\nå·¥ä½œåœ°é»ž:{jobAddrNoDesc}\né¡žåˆ¥ï¼š{coIndustryDesc}\né€£çµ:{link}\n=======================\n\nâ¤ï¸ðŸ§¡â¤ï¸ðŸ§¡â¤ï¸ðŸ§¡â¤ï¸ðŸ§¡â¤ï¸\n\n"
            if len(returnstrbox+strbox) > 6000:
                isreturn = True
                break
            returnstrbox += strbox
            strbox = ""
        except Exception as e:
            print(e)
    return returnstrbox.replace("&lt;", "<").replace("&gt;", ">")
